[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "NYC 311 Service Requests",
    "section": "",
    "text": "1 Introduction\nThe goal of this project to analyze the 311 service request dataset fetched from NYC OpenData and use various plots to visualize and identify trends to find answers to proposed questions."
  },
  {
    "objectID": "index.html#what-are-311-service-requests",
    "href": "index.html#what-are-311-service-requests",
    "title": "NYC 311 Service Requests",
    "section": "1.1 What are 311 Service Requests ?",
    "text": "1.1 What are 311 Service Requests ?\n311 service requests refer to the non emergency requests raised by the residents for municipal services. These service requests cover a broad range of non-urgent issues and concerns within a community, and they are typically handled by local government agencies.\nSome of the non urgent issues covered under 311 Service Requests -\n\nNoise Complaints\nGraffiti Removal\nAbandoned Vehicles\nReporting stray animals, animal nuisances, or other non-emergency animal-related issues.\nStreet and sidewalk maintenance\n\nThe 311 Service Requests can be raised by dialing the 311 telephone number or any of the other channels like mobile app or online portal"
  },
  {
    "objectID": "index.html#why-311-service-requests-are-important",
    "href": "index.html#why-311-service-requests-are-important",
    "title": "NYC 311 Service Requests",
    "section": "1.2 Why 311 Service Requests are important?",
    "text": "1.2 Why 311 Service Requests are important?\n311 service requests provide valuable insights into the challenges experienced by the city’s residents. Analyzing trends and patterns in these requests enables local governments to comprehend the prevalent issues within the community. These insights, in turn, become instrumental for urban planning, development strategies, and policy formulation aimed at enhancing community welfare.\nThrough this project, our goal is to pinpoint the most common issues faced by residents across various districts in New York City. This information is particularly invaluable for the student community as it offers a nuanced understanding of the quality of life and community welfare in different districts, aiding informed decisions when renting an apartment."
  },
  {
    "objectID": "index.html#questions-we-are-interested-in-studying--",
    "href": "index.html#questions-we-are-interested-in-studying--",
    "title": "NYC 311 Service Requests",
    "section": "1.3 Questions we are interested in studying -",
    "text": "1.3 Questions we are interested in studying -\n\nWhich borough has the most complaints, and the least??\nWhich complaint types are the most numerous, and the least?\nWhat are the locations that most complaints are associated with?\nWhat is the proportion of complaints that were closed by different departments?\nWhat types of complaints get closed the fastest/slowest, by using the mean resolution time to close a request?\nWhat are the trends in service requests over time?"
  },
  {
    "objectID": "data.html#description",
    "href": "data.html#description",
    "title": "2  Data",
    "section": "2.1 Description",
    "text": "2.1 Description\nSource of the data set - NYC OpenData Website\nDataset link: 311 Service Requests from 2010 to Present\nThe dataset is owned by NYC OpenData and the data was provided by 311 and Department of Information Technology and Telecommunications (DoITT) with the frequency of update set to daily. It offers a comprehensive view of service requests, particularly in terms of location specificity. There are multiple columns in the dataset using which we can help us pinpoint the exact location of the raised request.\nAs we have such a comprehensive dataset which gets updated daily, there are 34.1M rows with 41 columns in it. It covers all the service requests from 2010 till the present date.\nHowever we discovered the following issues with the dataset -\n\nDue to the large dataset size, downloading the dataset as csv becomes difficult (&gt;6GB in size).\nReading such a large dataset in memory also becomes an issue causing RStudio session to crash.\nMultiple columns in the dataset were redundant as they would help us in answering the proposed questions\nAnother issue is mentioned on the NYC OpenData website - Due to pandemic call handling modifications, the ‘Open Data Channel Type’ values may not accurately indicate the channel the Service Request was submitted in for the period starting March 2020.\nMany of the data visualization libraries (eg. VIM, narniar) fail for big datasets and raise errors. As a result, a subset of the dataset is necessary for visualization.\n\nAs a result, instead of reading the entire dataset starting with rows from the year 2010 till the current date, we have used a subset of the data of appropriate size (starting from Sept 2023 till Nov 2023).\nPlan for importing the dataset -\n\nSince the dataset size is big, we cannot directly download the data and then subset for usage. Instead NYC OpenData has a data exploration tool to filter records before exporting the dataset.\nWe used the tool to filter for records starting from Sept 2023 till the current date and also excluded the redundant columns.\nThe dataset was exported as a CSV file and then used for further analysis.\n\nThe dimensions of the subset: 837k rows by 32 columns, 350MB"
  },
  {
    "objectID": "data.html#research-plan",
    "href": "data.html#research-plan",
    "title": "2  Data",
    "section": "2.2 Research Plan",
    "text": "2.2 Research Plan\nAs seen in Section 1.3, these are the questions and the proposed methods we plan to adopt, to answer them. With these issues explored, it should give students an idea of which areas/streets are more problematic (more complaints; complaints of a non-trivial nature such as rat or noise issues; slow response speed by authorities to address them; ) and hence might be good to avoid.\n\nWhich borough has the most complaints, and the least?\n\nWe will plot the Borough features (eg. Borough) with a bar chart, sorted in descending order, to see which boroughs have the most/least complaints over the given time period. As this Borough feature has no missing values, we can use it to plot, without needing any data imputation. Locations with high number of complaints, may be less desirable to live in.\n\nWhich complaint types are the most numerous, and the least?\n\nSimilar to question 1, we can use a bar chart to do this exploration. We can use the feature “Complaint Type” for this visualisation. Certain complaint types are more significant (eg. persistent loud noises, rat issues), while some might be less bothersome, depending on one’s priorities (eg. illegal parking is less of an issue for student tenants, but more annoying for residents with cars).\n\nWhat are the locations that various complaint types are associated with?\n\nWe will make use of address features (eg. Borough, Street Name), and the Complaint Type feature, to plot multiple heatmaps (1 for each address feature). The higher the color intensity, the worse the area in terms of that Complaint Type’s count. Since Borough and Street Name features have very few missing values (0-3%), our plots would be a comprehensive representation of the dataset. Locations with high number of significant complaints, may be less desirable to live in.\n\nProportion of complaints that were closed by different departments?\n\nWe can plot the Agency feature, against the Complaint Type and the Status feature, using a mosaic plot, to see the types of complaints successfully closed/left unclosed by each agency. A low closure count may indicate ineffective responses by the authorities, and may not bode well for people living in that area especially if the complaints are serious in nature (eg. rodent issues).\n\nTypes of complaints that get closed the fastest/slowest, by using the mean resolution time to close a request.\n\nWe can use the Created and Closed Dates features to create a new column “Closing Duration”, aggregate the mean duration for each Complaint Type, and plot the mean Closing Duration against each Complaint Type. If necessary, we may use the median instead of the mean. We can plot this using a box/violin plot.\nBut to do so, we first need to pre-process the date related features, and convert the strings into timestamps, so as to calculate the duration.\nWe can also plot the mean Closing Duration, against the location features, using a chloropeth map, to see which locations close complaints the fastest/slowest.\nThese are also indicators of the effectiveness/responsiveness of the relevant authorities, depending on location and the issue at hand.\n\nWhat are the trends in service requests over time?\n\nWe can plot a time series line chart/ridgeline plot, using the Complaint Types (take the sum eg. for each Borough) plotted against time based features (Created Date, binned into weeks of the year). We could explore adding interactive filters to drill down into each location, to see the trend of different complaint types per location. A persistently high complaint count may be a bad sign for residents in the affected areas, or may indicate ineffective, non-permanent resolutions of issues by the relevant authorities - which all point towards a less-than-pleasant living environment.\n~~~\nFor all the above questions, depending on the results that we observe, we may drill down to lower level features. For example, for certain Boroughs with high number of complaints, we can drill down to Street/Zipcode/Community District levels, to investigate the specific areas that contribute most to the issue."
  },
  {
    "objectID": "data.html#missing-value-analysis",
    "href": "data.html#missing-value-analysis",
    "title": "2  Data",
    "section": "2.3 Missing value analysis",
    "text": "2.3 Missing value analysis\n\n\nCode\nlibrary(readr)\nlibrary(DataExplorer)\n# library(\"googledrive\")\n\n#load data\ndf &lt;- read_csv(\"C:\\\\Users\\\\varun\\\\Downloads\\\\311_Service_Requests_from_20230901_to_20231129.csv\",show_col_types = FALSE)\n# df &lt;- drive_read_string(\"https://drive.google.com/file/d/1UsYevTBsztmkhGO45Fubz1ToqzoeNHcV/view?usp=drive_link\", type = 'csv') #always needs authentication, may not be ideal.\n\n# plot % of missing values for columns \nplot_missing(df, title = \"% of missing values for Features (or columns)\", geom_label_args = list(\"size\" = 2))\n\n\n\n\n\nComments\n\nWe can see that the top few columns eg. Park Borough, Park Facility Name, till Created Date, comprise 0% missing values. That increases to 0.7%-3.7% from Address Type to Street Name. These are still in the Good range (&lt;5%, per documentation). One another observation is that the columns from Police Precincts till Borough Boundaries have the same percentage of missing values.\nFor City to Closed Date, the number of missing values rises to 5%-12%, in the OK range (&lt;5% to 40%). For Landmark, this increases to 40%, in the Bad range (&gt;40% to 80% range).\nFor Facility Type, Vehicle Type, Due Date, almost all rows (&gt;93%) have missing values, which is so high that the package parks them under the Remove range (&gt;80%).**\n\nDocumentation: “link”\n\n\nCode\nplot_intro(df)\n\n\n\n\n\nOnly the last 3 bars pertain to missing data values. The bars represent the following:\n\nBar 1. Discrete Columns: % of columns with discrete data\nBar 2. Continuous Columns: % of columns with continuous data\nBar 3. All Missing Columns: % of columns with everything missing\nBar 4. Complete Rows: % of rows with everything filled\nBar 5. Missing Observations: % of empty cells across whole dataset\n\nDocumentation: Pg11, from “introduce” function\nBar 3: There are no columns that are completely empty. However, this doesn’t mean that all columns are useful, as it still depends on the proportion of empty values for each column (seen in 1st visualisation above. Highly empty columns may not be as useful), and the relevance of the column to the questions we are answering.\nBar 4: There are also no rows that are completely filled. This might not be such a major problem, if the key columns that we’re interested in, are filled.\nBar 5: 12% of the entire dataset’s cells are empty. This is not such a big problem, if the key columns that we’re interested in, are filled."
  },
  {
    "objectID": "results.html#q5.-types-of-complaints-that-get-closed-the-fastestslowest-by-using-the-mean-resolution-time-to-close-a-request.",
    "href": "results.html#q5.-types-of-complaints-that-get-closed-the-fastestslowest-by-using-the-mean-resolution-time-to-close-a-request.",
    "title": "3  Results",
    "section": "3.1 Q5. Types of complaints that get closed the fastest/slowest, by using the mean resolution time to close a request.",
    "text": "3.1 Q5. Types of complaints that get closed the fastest/slowest, by using the mean resolution time to close a request.\nComplaints that get resolved the fastest\n\n\nCode\ncomplaint_duration &lt;- service_data %&gt;%\n  group_by(`Complaint Type`) %&gt;%\n  summarise(across(Closing_Duration,mean, na.rm=TRUE))\n\ncomplaint_duration[order(complaint_duration$Closing_Duration, decreasing = FALSE),] %&gt;%\n  slice(1:40) %&gt;%\n  ggplot(aes(x = Closing_Duration, y = fct_rev(\n    fct_reorder(`Complaint Type`, Closing_Duration, .desc = TRUE)\n  ))) +\n  geom_point() +\n  xlab(\"Closing Duration (Days)\") +\n  ylab(\"Complaint Type\") +\n  ggtitle(\"Mean Time for Complaint Resolution\")+\n  theme_bw()\n\n\n\n\n\nTop 40 Complaints that get resolved the slowest\n\n\nCode\ncomplaint_duration[order(complaint_duration$Closing_Duration, decreasing = TRUE),] %&gt;%\n  slice(1:40) %&gt;%\n  ggplot(aes(x = Closing_Duration, y = fct_rev(\n    fct_reorder(`Complaint Type`, Closing_Duration, .desc = TRUE)\n  ))) +\n  geom_point() +\n  xlab(\"Closing Duration\") +\n  ylab(\"Complaint Type\") +\n  ggtitle(\"Mean Time for Complaint Resolution (Days)\")+\n  theme_bw()\n\n\n\n\n\nComments:\nResolution time for tickets across Boroughs\n\n\nCode\nservice_data %&gt;% na.omit(service_data) %&gt;% \nggplot(aes(x = Borough ,y = Closing_Duration)) +\n  geom_boxplot() +\n  ggtitle(\"Boxplot for Ticket Closing Duration for each Borough\")+\n  labs(\n    x = \"Borough\",\n    y = \"Ticket Resolution Duration (Days)\"\n  ) +\n  theme_bw()\n\n\n\n\n\nComments:\nFrom the boxplots we can see that the median resolution time across different boroughs is nearly the same (Between 1-2 days). The outliers are mainly due to issues visualized in the previous Cleveland plot. A ridgeline plot was considered earlier to visualize instead of the boxplot but since most of the resolution times are close to 1-2 days, there was not a lot of information that could be derived from such a distribution.\nResolution time for tickets across Districts\n\n\nCode\nservice_district &lt;- service_data %&gt;%\n  group_by(`City Council Districts`) %&gt;%\n  summarise(mn_cd = mean(Closing_Duration, na.rm = TRUE)) %&gt;%\n  arrange(desc(mn_cd)) %&gt;%\n  rename(value = mn_cd) %&gt;%\n  drop_na(value) %&gt;%\n  mutate(`City Council Districts` = as.character(`City Council Districts`))\n\nnyc_boundaries(geography = \"council\") %&gt;%\n  left_join(service_district,\n            by = c(\"council_dist_id\" = \"City Council Districts\")) %&gt;%\n  ggplot() +\n  geom_sf(aes(fill = value)) +\n  scale_fill_viridis_c(name = \"Mean Resolution Time (Days)\",\n                       option = \"inferno\",\n                       direction = -1) +\n  theme_void() +\n  labs(title = \"How fast is the ticket resolution for each District?\")"
  },
  {
    "objectID": "results.html#q6.-what-are-the-trends-in-service-requests-over-time",
    "href": "results.html#q6.-what-are-the-trends-in-service-requests-over-time",
    "title": "3  Results",
    "section": "3.2 Q6. What are the trends in service requests over time?",
    "text": "3.2 Q6. What are the trends in service requests over time?\n\n\nCode\nservice_data$week_number &lt;- week(ymd(service_data$`Created Date`))\n\n\nDensity Histogram to understand the distribution of ticket creation over each week\n\n\nCode\nggplot(service_data, aes(x = week_number)) +\n  geom_histogram(\n    aes(y = after_stat(density)),\n    color = \"black\",\n    fill = \"#CC5500\",\n    binwidth = 1,\n    right = FALSE\n  ) +\n  ggtitle(\"Density Histogram for 311 Tickets created every week (Sept-Nov)\") +\n  theme_bw()\n\n\n\n\n\nLine plot for easy comparison of ticket creation every week across different Boroughs\n\n\nCode\ncustom_colors &lt;- c(\"QUEENS\" = \"yellow\",\"MANHATTAN\"=\"blue\",\"BRONX\"=\"brown\",\"STATEN ISLAND\" = \"green\", \"BROOKLYN\" = \"red\")\naggregate(\n  service_data$`Complaint Type`,\n  by = list(service_data$Borough, service_data$week_number),\n  FUN = length\n) %&gt;%\n  rename(issue_count = x,\n         week_number = Group.2,\n         Borough = Group.1) %&gt;%\n  ggplot(aes(x = week_number, y = issue_count, color = Borough)) +\n  geom_line() +\n  scale_color_manual(values = custom_colors) +\n  ggtitle(\"Tickets created in different Boroughs for each week (Sept-Nov)\") +\n  labs(x = \"Week Number\", y = \"Created Tickets count\") +\n  theme_bw()\n\n\n\n\n\nComments:\nThere definitely is a pattern as week 40 has the highest ticket creation count across all the Boroughs.\nWeek 35 and Week 48 have the lowest ticket counts as the dataset from Sept 01 till the Nov29. Sept 01 is a Friday and so week 35 just has ticket counts for Friday and Saturday instead of the entire week. Similary, the entire week data for week 48 was not used.\nWe now analyze week 40 to understand the type of issue causing the peak\n\n\nCode\nweek_40_highest &lt;- aggregate(\n  service_data$`Complaint Type`,\n  by = list(service_data$`Complaint Type`,service_data$Borough, service_data$week_number),\n  FUN = length\n) %&gt;% \n  filter(Group.3 == 40) %&gt;% \n  group_by(Group.2) %&gt;% summarise(max_x = max(x),.groups = 'drop') %&gt;% \n  arrange(desc(max_x)) %&gt;% \n  rename(Borough = Group.2, Tickets = max_x)\n\naggregate(\n  service_data$`Complaint Type`,\n  by = list(service_data$`Complaint Type`,service_data$Borough, service_data$week_number),\n  FUN = length\n) %&gt;% \n  filter(Group.3 == 40) %&gt;% \n  arrange(desc(x)) %&gt;% \n  rename(Issue = Group.1,week_number = Group.3,Borough = Group.2, Tickets = x) %&gt;% \n  inner_join(week_40_highest,by=c(\"Borough\" = \"Borough\",\"Tickets\" = \"Tickets\"))\n\n\n            Issue       Borough week_number Tickets\n1 Illegal Parking      BROOKLYN          40    3629\n2 Illegal Parking        QUEENS          40    2795\n3 Illegal Parking     MANHATTAN          40    1454\n4 Illegal Parking         BRONX          40    1445\n5 Illegal Parking STATEN ISLAND          40     296\n\n\nComment:\nAlthough there are many issues contributing to the peak on Week 40, Illegal Parking contributes the most"
  },
  {
    "objectID": "d3graph.html",
    "href": "d3graph.html",
    "title": "4  Interactive graph",
    "section": "",
    "text": "Add bar\n\n\nRemove bar"
  }
]